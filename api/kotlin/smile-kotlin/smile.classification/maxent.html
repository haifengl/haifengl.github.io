<HTML>
<HEAD>
<meta charset="UTF-8">
<title>maxent - smile-kotlin</title>
<link rel="stylesheet" href="../../style.css">
</HEAD>
<BODY>
<a href="../index.html">smile-kotlin</a>&nbsp;/&nbsp;<a href="index.html">smile.classification</a>&nbsp;/&nbsp;<a href="./maxent.html">maxent</a><br/>
<br/>
<h1>maxent</h1>
<a name="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)"></a>
<code><span class="keyword">fun </span><span class="identifier">maxent</span><span class="symbol">(</span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/x">x</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/index.html"><span class="identifier">Array</span></a><span class="symbol">&lt;</span><a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int-array/index.html"><span class="identifier">IntArray</span></a><span class="symbol">&gt;</span><span class="symbol">, </span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/y">y</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int-array/index.html"><span class="identifier">IntArray</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/p">p</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html"><span class="identifier">Int</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/lambda">lambda</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double/index.html"><span class="identifier">Double</span></a>&nbsp;<span class="symbol">=</span>&nbsp;0.1<span class="symbol">, </span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/tol">tol</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double/index.html"><span class="identifier">Double</span></a>&nbsp;<span class="symbol">=</span>&nbsp;1E-5<span class="symbol">, </span><span class="identifier" id="smile.classification$maxent(kotlin.Array((kotlin.IntArray)), kotlin.IntArray, kotlin.Int, kotlin.Double, kotlin.Double, kotlin.Int)/maxIter">maxIter</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html"><span class="identifier">Int</span></a>&nbsp;<span class="symbol">=</span>&nbsp;500<span class="symbol">)</span><span class="symbol">: </span><a href="http://haifengl.github.io/api/java/smile/classification/Maxent.html"><span class="identifier">Maxent</span></a></code>
<p>Maximum entropy classifier.
Maximum entropy is a technique for learning
probability distributions from data. In maximum entropy models, the
observed data itself is assumed to be the testable information. Maximum
entropy models don't assume anything about the probability distribution
other than what have been observed and always choose the most uniform
distribution subject to the observed constraints.</p>
<p>Basically, maximum entropy classifier is another name of multinomial logistic
regression applied to categorical independent variables, which are
converted to binary dummy variables. Maximum entropy models are widely
used in natural language processing.  Here, we provide an implementation
which assumes that binary features are stored in a sparse array, of which
entries are the indices of nonzero features.</p>
<p>====References:====</p>
<ul><li>A. L. Berger, S. D. Pietra, and V. J. D. Pietra. A maximum entropy approach to natural language processing. Computational Linguistics 22(1):39-71, 1996.</li>
</ul>
<h3>Parameters</h3>
<p><a name="x"></a>
<code>x</code> - training samples. Each sample is represented by a set of sparse
    binary features. The features are stored in an integer array, of which
    are the indices of nonzero features.</p>
<p><a name="y"></a>
<code>y</code> - training labels in [0, k), where k is the number of classes.</p>
<p><a name="p"></a>
<code>p</code> - the dimension of feature space.</p>
<p><a name="lambda"></a>
<code>lambda</code> - &lambda; &gt; 0 gives a "regularized" estimate of linear
    weights which often has superior generalization performance, especially
    when the dimensionality is high.</p>
<p><a name="tol"></a>
<code>tol</code> - tolerance for stopping iterations.</p>
<p><a name="maxIter"></a>
<code>maxIter</code> - maximum number of iterations.</p>
<p><strong>Return</strong><br/>
Maximum entropy model.</p>
</BODY>
</HTML>
