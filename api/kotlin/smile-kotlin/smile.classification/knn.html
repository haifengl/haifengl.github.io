<HTML>
<HEAD>
<meta charset="UTF-8">
<title>knn - smile-kotlin</title>
<link rel="stylesheet" href="../../style.css">
</HEAD>
<BODY>
<a href="../index.html">smile-kotlin</a>&nbsp;/&nbsp;<a href="index.html">smile.classification</a>&nbsp;/&nbsp;<a href="./knn.html">knn</a><br/>
<br/>
<h1>knn</h1>
<a name="smile.classification$knn(smile.neighbor.KNNSearch((smile.classification.knn.T, )), kotlin.IntArray, kotlin.Int)"></a>
<code><span class="keyword">fun </span><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span> <span class="identifier">knn</span><span class="symbol">(</span><span class="identifier" id="smile.classification$knn(smile.neighbor.KNNSearch((smile.classification.knn.T, )), kotlin.IntArray, kotlin.Int)/x">x</span><span class="symbol">:</span>&nbsp;<a href="http://haifengl.github.io/api/java/smile/neighbor/KNNSearch.html"><span class="identifier">KNNSearch</span></a><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">,</span>&nbsp;<span class="identifier">T</span><span class="symbol">&gt;</span><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(smile.neighbor.KNNSearch((smile.classification.knn.T, )), kotlin.IntArray, kotlin.Int)/y">y</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int-array/index.html"><span class="identifier">IntArray</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(smile.neighbor.KNNSearch((smile.classification.knn.T, )), kotlin.IntArray, kotlin.Int)/k">k</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html"><span class="identifier">Int</span></a><span class="symbol">)</span><span class="symbol">: </span><a href="http://haifengl.github.io/api/java/smile/classification/KNN.html"><span class="identifier">KNN</span></a><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span></code>
<p>K-nearest neighbor classifier.
The k-nearest neighbor algorithm (k-NN) is
a method for classifying objects by a majority vote of its neighbors,
with the object being assigned to the class most common amongst its k
nearest neighbors (k is a positive integer, typically small).
k-NN is a type of instance-based learning, or lazy learning where the
function is only approximated locally and all computation
is deferred until classification.</p>
<p>The best choice of k depends upon the data; generally, larger values of
k reduce the effect of noise on the classification, but make boundaries
between classes less distinct. A good k can be selected by various
heuristic techniques, e.g. cross-validation. In binary problems, it is
helpful to choose k to be an odd number as this avoids tied votes.</p>
<p>A drawback to the basic majority voting classification is that the classes
with the more frequent instances tend to dominate the prediction of the
new object, as they tend to come up in the k nearest neighbors when
the neighbors are computed due to their large number. One way to overcome
this problem is to weight the classification taking into account the
distance from the test point to each of its k nearest neighbors.</p>
<p>Often, the classification accuracy of k-NN can be improved significantly
if the distance metric is learned with specialized algorithms such as
Large Margin Nearest Neighbor or Neighborhood Components Analysis.</p>
<p>Nearest neighbor rules in effect compute the decision boundary in an
implicit manner. It is also possible to compute the decision boundary
itself explicitly, and to do so in an efficient manner so that the
computational complexity is a function of the boundary complexity.</p>
<p>The nearest neighbor algorithm has some strong consistency results. As
the amount of data approaches infinity, the algorithm is guaranteed to
yield an error rate no worse than twice the Bayes error rate (the minimum
achievable error rate given the distribution of the data). k-NN is
guaranteed to approach the Bayes error rate, for some value of k (where k
increases as a function of the number of data points).</p>
<h3>Parameters</h3>
<p><a name="x"></a>
<code>x</code> - k-nearest neighbor search data structure of training instances.</p>
<p><a name="y"></a>
<code>y</code> - training labels in [0, c), where c is the number of classes.</p>
<p><a name="k"></a>
<code>k</code> - the number of neighbors for classification.</p>
<a name="smile.classification$knn(kotlin.Array((smile.classification.knn.T)), kotlin.IntArray, kotlin.Int, smile.math.distance.Distance((smile.classification.knn.T)))"></a>
<code><span class="keyword">fun </span><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span> <span class="identifier">knn</span><span class="symbol">(</span><span class="identifier" id="smile.classification$knn(kotlin.Array((smile.classification.knn.T)), kotlin.IntArray, kotlin.Int, smile.math.distance.Distance((smile.classification.knn.T)))/x">x</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/index.html"><span class="identifier">Array</span></a><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(kotlin.Array((smile.classification.knn.T)), kotlin.IntArray, kotlin.Int, smile.math.distance.Distance((smile.classification.knn.T)))/y">y</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int-array/index.html"><span class="identifier">IntArray</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(kotlin.Array((smile.classification.knn.T)), kotlin.IntArray, kotlin.Int, smile.math.distance.Distance((smile.classification.knn.T)))/k">k</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html"><span class="identifier">Int</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(kotlin.Array((smile.classification.knn.T)), kotlin.IntArray, kotlin.Int, smile.math.distance.Distance((smile.classification.knn.T)))/distance">distance</span><span class="symbol">:</span>&nbsp;<a href="http://haifengl.github.io/api/java/smile/math/distance/Distance.html"><span class="identifier">Distance</span></a><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span><span class="symbol">)</span><span class="symbol">: </span><a href="http://haifengl.github.io/api/java/smile/classification/KNN.html"><span class="identifier">KNN</span></a><span class="symbol">&lt;</span><span class="identifier">T</span><span class="symbol">&gt;</span></code>
<p>K-nearest neighbor classifier.</p>
<h3>Parameters</h3>
<p><a name="x"></a>
<code>x</code> - training samples.</p>
<p><a name="y"></a>
<code>y</code> - training labels in [0, c), where c is the number of classes.</p>
<p><a name="distance"></a>
<code>distance</code> - the distance measure for finding nearest neighbors.</p>
<p><a name="k"></a>
<code>k</code> - the number of neighbors for classification.</p>
<a name="smile.classification$knn(kotlin.Array((kotlin.DoubleArray)), kotlin.IntArray, kotlin.Int)"></a>
<code><span class="keyword">fun </span><span class="identifier">knn</span><span class="symbol">(</span><span class="identifier" id="smile.classification$knn(kotlin.Array((kotlin.DoubleArray)), kotlin.IntArray, kotlin.Int)/x">x</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/index.html"><span class="identifier">Array</span></a><span class="symbol">&lt;</span><a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double-array/index.html"><span class="identifier">DoubleArray</span></a><span class="symbol">&gt;</span><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(kotlin.Array((kotlin.DoubleArray)), kotlin.IntArray, kotlin.Int)/y">y</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int-array/index.html"><span class="identifier">IntArray</span></a><span class="symbol">, </span><span class="identifier" id="smile.classification$knn(kotlin.Array((kotlin.DoubleArray)), kotlin.IntArray, kotlin.Int)/k">k</span><span class="symbol">:</span>&nbsp;<a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html"><span class="identifier">Int</span></a><span class="symbol">)</span><span class="symbol">: </span><a href="http://haifengl.github.io/api/java/smile/classification/KNN.html"><span class="identifier">KNN</span></a><span class="symbol">&lt;</span><a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double-array/index.html"><span class="identifier">DoubleArray</span></a><span class="symbol">&gt;</span></code>
<p>K-nearest neighbor classifier with Euclidean distance as the similarity measure.</p>
<h3>Parameters</h3>
<p><a name="x"></a>
<code>x</code> - training samples.</p>
<p><a name="y"></a>
<code>y</code> - training labels in [0, c), where c is the number of classes.</p>
<p><a name="k"></a>
<code>k</code> - the number of neighbors for classification.</p>
</BODY>
</HTML>
