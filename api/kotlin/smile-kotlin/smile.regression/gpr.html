<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" charset="UTF-8">
    <title>gpr</title>
<link href="../../images/logo-icon.svg" rel="icon" type="image/svg"><script>var pathToRoot = "../../";</script><script type="text/javascript" src="../../scripts/sourceset_dependencies.js" async="async"></script><link href="../../styles/style.css" rel="Stylesheet"><link href="../../styles/logo-styles.css" rel="Stylesheet"><link href="../../styles/jetbrains-mono.css" rel="Stylesheet"><link href="../../styles/main.css" rel="Stylesheet"><script type="text/javascript" src="../../scripts/clipboard.js" async="async"></script><script type="text/javascript" src="../../scripts/navigation-loader.js" async="async"></script><script type="text/javascript" src="../../scripts/platform-content-handler.js" async="async"></script><script type="text/javascript" src="../../scripts/main.js" async="async"></script>  </head>
  <body>
    <div id="container">
      <div id="leftColumn"><a href="../../index.html">
          <div id="logo"></div>
        </a>
        <div id="paneSearch"></div>
        <div id="sideMenu"></div>
      </div>
      <div id="main">
        <div id="leftToggler"><span class="icon-toggler"></span></div>
<script type="text/javascript" src="../../scripts/main.js"></script>        <div class="main-content" id="content" pageIds="smile-kotlin::smile.regression//gpr/#kotlin.Array[TypeParam(bounds=[kotlin.Any?])]#kotlin.DoubleArray#smile.math.kernel.MercerKernel[TypeParam(bounds=[kotlin.Any?])]#kotlin.Double#kotlin.Boolean#kotlin.Double#kotlin.Int/PointingToDeclaration//769193423">
          <div class="navigation-wrapper" id="navigation-wrapper">
            <div class="breadcrumbs"><a href="../../index.html">smile-kotlin</a>/<a href="index.html">smile.regression</a>/<a href="gpr.html">gpr</a></div>
            <div class="pull-right d-flex">
              <div id="searchBar"></div>
            </div>
          </div>
          <div class="cover ">
            <h1 class="cover"><span><span>gpr</span></span></h1>
          </div>
<div class="divergent-group" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="with-platform-tags"><span class="pull-right"></span></div>

  <div>
    <div class="platform-hinted " data-platform-hinted="data-platform-hinted"><div class="content sourceset-depenent-content" data-active="" data-togglable=":dokkaHtml/main"><div class="symbol monospace">fun &lt;<a href="gpr.html">T</a>&gt; <a href="gpr.html">gpr</a>(x: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-array/index.html">Array</a>&lt;<a href="gpr.html">T</a>&gt;, y: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double-array/index.html">DoubleArray</a>, kernel: <span data-unresolved-link="smile.math.kernel/MercerKernel///PointingToDeclaration/">MercerKernel</span>&lt;<a href="gpr.html">T</a>&gt;, noise: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double/index.html">Double</a>, normalize: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-boolean/index.html">Boolean</a> = true, tol: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-double/index.html">Double</a> = 1E-5, maxIter: <a href="https://kotlinlang.org/api/latest/jvm/stdlib/kotlin/-int/index.html">Int</a> = 0): <span data-unresolved-link="smile.regression/GaussianProcessRegression///PointingToDeclaration/">GaussianProcessRegression</span>&lt;<a href="gpr.html">T</a>&gt;<span class="top-right-position"><span class="copy-icon"></span><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div></span></div></div></div>
  </div>
<p class="paragraph">Gaussian Process for Regression. A Gaussian process is a stochastic process whose realizations consist of random values associated with every point in a range of times (or of space) such that each such random variable has a normal distribution. Moreover, every finite collection of those random variables has a multivariate normal distribution.</p><p class="paragraph">A Gaussian process can be used as a prior probability distribution over functions in Bayesian inference. Given any set of N points in the desired domain of your functions, take a multivariate Gaussian whose covariance matrix parameter is the Gram matrix of N points with some desired kernel, and sample from that Gaussian. Inference of continuous values with a Gaussian process prior is known as Gaussian process regression.</p><p class="paragraph">The fitting is performed in the reproducing kernel Hilbert space with the &quot;kernel trick&quot;. The loss function is squared-error. This also arises as the kriging estimate of a Gaussian random field in spatial statistics.</p><p class="paragraph">A significant problem with Gaussian process prediction is that it typically scales as O(n<sup>3</sup>). For large problems (e.g. n > 10,000) both storing the Gram matrix and solving the associated linear systems are prohibitive on modern workstations. An extensive range of proposals have been suggested to deal with this problem. A popular approach is the reduced-rank Approximations of the Gram Matrix, known as Nystrom approximation. Greedy approximation is another popular approach that uses an active set of training points of size m selected from the training set of size n > m. We assume that it is impossible to search for the optimal subset of size m due to combinatorics. The points in the active set could be selected randomly, but in general we might expect better performance if the points are selected greedily w.r.t. some criterion. Recently, researchers had proposed relaxing the constraint that the inducing variables must be a subset of training/test cases, turning the discrete selection problem into one of continuous optimization.</p><p class="paragraph">This method fits a regular Gaussian process model.</p><p class="paragraph">====References:====</p><ul><li><p class="paragraph">Carl Edward Rasmussen and Chris Williams. Gaussian Processes for Machine Learning, 2006.</p></li><li><p class="paragraph">Joaquin Quinonero-candela,  Carl Edward Ramussen,  Christopher K. I. Williams. Approximation Methods for Gaussian Process Regression. 2007.</p></li><li><p class="paragraph">T. Poggio and F. Girosi. Networks for approximation and learning. Proc. IEEE 78(9):1484-1487, 1990.</p></li><li><p class="paragraph">Kai Zhang and James T. Kwok. Clustered Nystrom Method for Large Scale Manifold Learning and Dimension Reduction. IEEE Transactions on Neural Networks, 2010.</p></li></ul><h2 class="">Parameters</h2><div data-togglable="Parameters"><div class="platform-hinted WithExtraAttributes" data-platform-hinted="data-platform-hinted" data-togglable="Parameters"><div class="content sourceset-depenent-content" data-active="" data-togglable=":dokkaHtml/main"><div data-togglable="Parameters"><div class="table" data-togglable="Parameters"><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>x</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the training dataset.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>y</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the response variable.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>kernel</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the Mercer kernel.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>noise</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the noise variance, which also works as a regularization parameter.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>normalize</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the option to normalize the response variable.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span><span>tol</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the stopping tolerance for HPO.</p></div></div></div></div></div><div class="table-row" data-filterable-current=":dokkaHtml/main" data-filterable-set=":dokkaHtml/main"><div class="main-subrow keyValue WithExtraAttributes"><div class=""><span class="inline-flex"><span>max</span><wbr></wbr><span><span>Iter</span></span></span></div><div><div class="title"><div data-togglable="Parameters"><p class="paragraph">the maximum number of iterations for HPO. No HPO if maxIter <= 0.</p></div></div></div></div></div></div></div></div></div></div></div>
        </div>
        <div class="footer"><span class="go-to-top-icon"><a href="#content"></a></span><span>Â© 2022 Copyright</span><span class="pull-right"><span>Generated by </span><a href="https://github.com/Kotlin/dokka"><span>dokka</span><span class="padded-icon"></span></a></span></div>
      </div>
    </div>
  </body>
</html>

