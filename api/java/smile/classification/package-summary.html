<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (21) on Tue Apr 23 19:09:50 EDT 2024 -->
<title>smile.classification</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-04-23">
<meta name="description" content="declaration: package: smile.classification">
<meta name="generator" content="javadoc/PackageWriterImpl">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../script-dir/jquery-ui.min.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-ui.min.js"></script>
<script type="text/javascript" src="../../script-dir/gtag.js"></script>
</head>
<body class="package-declaration-page">
<script type="text/javascript">var pathtoroot = "../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../index.html">Overview</a></li>
<li class="nav-bar-cell1-rev">Package</li>
<li>Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html#package">Help</a></li>
</ul>
<ul class="sub-nav-list-small">
<li>
<p>Package:</p>
<ul>
<li><a href="#package-description">Description</a></li>
<li>Related Packages</li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list">
<ul class="sub-nav-list">
<li>Package:&nbsp;</li>
<li><a href="#package-description">Description</a>&nbsp;|&nbsp;</li>
<li>Related Packages&nbsp;|&nbsp;</li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</div>
<div class="nav-list-search"><a href="../../search.html">SEARCH</a>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<div class="header">
<h1 title="Package smile.classification" class="title">Package smile.classification</h1>
</div>
<hr>
<div class="package-signature">package <span class="element-name">smile.classification</span></div>
<section class="package-description" id="package-description">
<div class="block">Classification algorithms. In machine learning and pattern recognition,
 classification refers to an algorithmic procedure for assigning a given
 input object into one of a given number of categories. The input
 object is formally termed an instance, and the categories are termed classes.
 <p>
 The instance is usually described by a vector of features, which together
 constitute a description of all known characteristics of the instance.
 Typically, features are either categorical (also known as nominal, i.e.
 consisting of one of a set of unordered items, such as a gender of "male"
 or "female", or a blood type of "A", "B", "AB" or "O"), ordinal (consisting
 of one of a set of ordered items, e.g. "large", "medium" or "small"),
 integer-valued (e.g. a count of the number of occurrences of a particular
 word in an email) or real-valued (e.g. a measurement of blood pressure).
 <p>
 Classification normally refers to a supervised procedure, i.e. a procedure
 that produces an inferred function to predict the output value of new
 instances based on a training set of pairs consisting of an input object
 and a desired output value. The inferred function is called a classifier
 if the output is discrete or a regression function if the output is
 continuous.
 <p>
 The inferred function should predict the correct output value for any valid
 input object. This requires the learning algorithm to generalize from the
 training data to unseen situations in a "reasonable" way.
 <p>
 A wide range of supervised learning algorithms is available, each with
 its strengths and weaknesses. There is no single learning algorithm that
 works best on all supervised learning problems. The most widely used
 learning algorithms are AdaBoost and gradient boosting, support vector
 machines, linear regression, linear discriminant analysis, logistic
 regression, naive Bayes, decision trees, k-nearest neighbor algorithm,
 and neural networks (multilayer perceptron).
 <p>
 If the feature vectors include features of many different kinds (discrete,
 discrete ordered, counts, continuous values), some algorithms cannot be
 easily applied. Many algorithms, including linear regression, logistic
 regression, neural networks, and nearest neighbor methods, require that
 the input features be numerical and scaled to similar ranges (e.g., to
 the [-1,1] interval). Methods that employ a distance function, such as
 nearest neighbor methods and support vector machines with Gaussian kernels,
 are particularly sensitive to this. An advantage of decision trees (and
 boosting algorithms based on decision trees) is that they easily handle
 heterogeneous data.
 <p>
 If the input features contain redundant information (e.g., highly correlated
 features), some learning algorithms (e.g., linear regression, logistic
 regression, and distance based methods) will perform poorly because of
 numerical instabilities. These problems can often be solved by imposing
 some form of regularization.
 <p>
 If each of the features makes an independent contribution to the output,
 then algorithms based on linear functions (e.g., linear regression,
 logistic regression, linear support vector machines, naive Bayes) generally
 perform well. However, if there are complex interactions among features,
 then algorithms such as nonlinear support vector machines, decision trees
 and neural networks work better. Linear methods can also be applied, but
 the engineer must manually specify the interactions when using them.
 <p>
 There are several major issues to consider in supervised learning:
 <dl>
 <dt>Features</dt>
 <dd>The accuracy of the inferred function depends strongly on how the input
 object is represented. Typically, the input object is transformed into
 a feature vector, which contains a number of features that are descriptive
 of the object. The number of features should not be too large, because of
 the curse of dimensionality; but should contain enough information to
 accurately predict the output.<p>
 There are many algorithms for feature selection that seek to identify
 the relevant features and discard the irrelevant ones. More generally,
 dimensionality reduction may seek to map the input data into a lower
 dimensional space prior to running the supervised learning algorithm.</dd>
 <dt>Over-fitting</dt>
 <dd>Over-fitting occurs when a statistical model describes random error
 or noise instead of the underlying relationship. Over-fitting generally
 occurs when a model is excessively complex, such as having too many
 parameters relative to the number of observations. A model which has
 been over-fit will generally have poor predictive performance, as it can
 exaggerate minor fluctuations in the data.
 <p>
 The potential for over-fitting depends not only on the number of parameters
 and data but also the conformability of the model structure with the data
 shape, and the magnitude of model error compared to the expected level
 of noise or error in the data.
 <p>
 In order to avoid over-fitting, it is necessary to use additional techniques
 (e.g. cross-validation, regularization, early stopping, pruning, Bayesian
 priors on parameters or model comparison), that can indicate when further
 training is not resulting in better generalization. The basis of some
 techniques is either (1) to explicitly penalize overly complex models,
 or (2) to test the model's ability to generalize by evaluating its
 performance on a set of data not used for training, which is assumed to
 approximate the typical unseen data that a model will encounter.</dd>
 <dt>Regularization</dt>
 <dd>Regularization involves introducing additional information in order
 to solve an ill-posed problem or to prevent over-fitting. This information
 is usually of the form of a penalty for complexity, such as restrictions
 for smoothness or bounds on the vector space norm.
 <p>
 A theoretical justification for regularization is that it attempts to impose
 Occam's razor on the solution. From a Bayesian point of view, many
 regularization techniques correspond to imposing certain prior distributions
 on model parameters.</dd>
 <dt>Bias-variance tradeoff</dt>
 <dd>Mean squared error (MSE) can be broken down into two components:
 variance and squared bias, known as the bias-variance decomposition.
 Thus in order to minimize the MSE, we need to minimize both the bias and
 the variance. However, this is not trivial. Therefore, there is a tradeoff
 between bias and variance.</dd>
 </dl></div>
</section>
<section class="summary">
<ul class="summary-list">
<li>
<div id="class-summary">
<div class="table-tabs" role="tablist" aria-orientation="horizontal"><button id="class-summary-tab0" role="tab" aria-selected="true" aria-controls="class-summary.tabpanel" tabindex="0" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary', 2)" class="active-table-tab">All Classes and Interfaces</button><button id="class-summary-tab1" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab1', 2)" class="table-tab">Interfaces</button><button id="class-summary-tab2" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab2', 2)" class="table-tab">Classes</button><button id="class-summary-tab3" role="tab" aria-selected="false" aria-controls="class-summary.tabpanel" tabindex="-1" onkeydown="switchTab(event)" onclick="show('class-summary', 'class-summary-tab3', 2)" class="table-tab">Enum Classes</button></div>
<div id="class-summary.tabpanel" role="tabpanel">
<div class="summary-table two-column-summary" aria-labelledby="class-summary-tab0">
<div class="table-header col-first">Class</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="AbstractClassifier.html" title="class in smile.classification">AbstractClassifier</a>&lt;T&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Abstract base class of classifiers.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="AdaBoost.html" title="class in smile.classification">AdaBoost</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">AdaBoost (Adaptive Boosting) classifier with decision trees.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab1"><a href="Classifier.html" title="interface in smile.classification">Classifier</a>&lt;T&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab1">
<div class="block">A classifier assigns an input object into one of a given number of categories.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab1"><a href="Classifier.Trainer.html" title="interface in smile.classification">Classifier.Trainer</a>&lt;T,<wbr>M extends <a href="Classifier.html" title="interface in smile.classification">Classifier</a>&lt;T&gt;&gt;</div>
<div class="col-last odd-row-color class-summary class-summary-tab1">
<div class="block">The classifier trainer.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="ClassLabels.html" title="class in smile.classification">ClassLabels</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Map arbitrary class labels to [0, k), where k is the number of classes.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab1"><a href="DataFrameClassifier.html" title="interface in smile.classification">DataFrameClassifier</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab1">
<div class="block">Classification trait on DataFrame.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab1"><a href="DataFrameClassifier.Trainer.html" title="interface in smile.classification">DataFrameClassifier.Trainer</a>&lt;M extends <a href="DataFrameClassifier.html" title="interface in smile.classification">DataFrameClassifier</a>&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab1">
<div class="block">The classifier trainer.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="DecisionTree.html" title="class in smile.classification">DecisionTree</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Decision tree.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="DiscreteNaiveBayes.html" title="class in smile.classification">DiscreteNaiveBayes</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Naive Bayes classifier for document classification in NLP.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab3"><a href="DiscreteNaiveBayes.Model.html" title="enum class in smile.classification">DiscreteNaiveBayes.Model</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab3">
<div class="block">The generation models of naive Bayes classifier.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="FLD.html" title="class in smile.classification">FLD</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Fisher's linear discriminant.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="GradientTreeBoost.html" title="class in smile.classification">GradientTreeBoost</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Gradient boosting for classification.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="IsotonicRegressionScaling.html" title="class in smile.classification">IsotonicRegressionScaling</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">A method to calibrate decision function value to probability.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="KNN.html" title="class in smile.classification">KNN</a>&lt;T&gt;</div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">K-nearest neighbor classifier.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="LDA.html" title="class in smile.classification">LDA</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Linear discriminant analysis.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="LogisticRegression.html" title="class in smile.classification">LogisticRegression</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Logistic regression.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="LogisticRegression.Binomial.html" title="class in smile.classification">LogisticRegression.Binomial</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Binomial logistic regression.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="LogisticRegression.Multinomial.html" title="class in smile.classification">LogisticRegression.Multinomial</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Multinomial logistic regression.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="Maxent.html" title="class in smile.classification">Maxent</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Maximum Entropy Classifier.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="Maxent.Binomial.html" title="class in smile.classification">Maxent.Binomial</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Binomial maximum entropy classifier.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="Maxent.Multinomial.html" title="class in smile.classification">Maxent.Multinomial</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Multinomial maximum entropy classifier.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="MLP.html" title="class in smile.classification">MLP</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Fully connected multilayer perceptron neural network for classification.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="NaiveBayes.html" title="class in smile.classification">NaiveBayes</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Naive Bayes classifier.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="OneVersusOne.html" title="class in smile.classification">OneVersusOne</a>&lt;T&gt;</div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">One-vs-one strategy for reducing the problem of
 multiclass classification to multiple binary classification problems.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="OneVersusRest.html" title="class in smile.classification">OneVersusRest</a>&lt;T&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">One-vs-rest (or one-vs-all) strategy for reducing the problem of
 multiclass classification to multiple binary classification problems.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="PlattScaling.html" title="class in smile.classification">PlattScaling</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Platt scaling or Platt calibration is a way of transforming the outputs
 of a classification model into a probability distribution over classes.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="QDA.html" title="class in smile.classification">QDA</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Quadratic discriminant analysis.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="RandomForest.html" title="class in smile.classification">RandomForest</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Random forest for classification.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="RandomForest.Model.html" title="class in smile.classification">RandomForest.Model</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">The base model.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="RBFNetwork.html" title="class in smile.classification">RBFNetwork</a>&lt;T&gt;</div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Radial basis function networks.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="RDA.html" title="class in smile.classification">RDA</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Regularized discriminant analysis.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="SparseLogisticRegression.html" title="class in smile.classification">SparseLogisticRegression</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Logistic regression on sparse data.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="SparseLogisticRegression.Binomial.html" title="class in smile.classification">SparseLogisticRegression.Binomial</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Binomial logistic regression.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="SparseLogisticRegression.Multinomial.html" title="class in smile.classification">SparseLogisticRegression.Multinomial</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Multinomial logistic regression.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="SVM.html" title="class in smile.classification">SVM</a>&lt;T&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Support vector machines for classification.</div>
</div>
</div>
</div>
</div>
</li>
</ul>
</section>
</main>
<footer role="contentinfo">
<hr>
<p class="legal-copy"><small>Copyright &copy; 2010-2024 Haifeng Li. All rights reserved.
Use is subject to <a href="https://raw.githubusercontent.com/haifengl/smile/master/LICENSE">license terms.</a>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-57GD08QCML"></script></small></p>
</footer>
</div>
</div>
</body>
</html>
