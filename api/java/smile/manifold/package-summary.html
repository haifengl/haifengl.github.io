<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (21) on Thu Apr 25 14:29:45 EDT 2024 -->
<title>smile.manifold</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="dc.created" content="2024-04-25">
<meta name="description" content="declaration: package: smile.manifold">
<meta name="generator" content="javadoc/PackageWriterImpl">
<link rel="stylesheet" type="text/css" href="../../stylesheet.css" title="Style">
<link rel="stylesheet" type="text/css" href="../../script-dir/jquery-ui.min.css" title="Style">
<script type="text/javascript" src="../../script.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-3.6.1.min.js"></script>
<script type="text/javascript" src="../../script-dir/jquery-ui.min.js"></script>
<script type="text/javascript" src="../../script-dir/gtag.js"></script>
</head>
<body class="package-declaration-page">
<script type="text/javascript">var pathtoroot = "../../";
loadScripts(document, 'script');</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<div class="flex-box">
<header role="banner" class="flex-header">
<nav role="navigation">
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="top-nav" id="navbar-top"><button id="navbar-toggle-button" aria-controls="navbar-top" aria-expanded="false" aria-label="Toggle navigation links"><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span><span class="nav-bar-toggle-icon">&nbsp;</span></button>
<div class="skip-nav"><a href="#skip-navbar-top" title="Skip navigation links">Skip navigation links</a></div>
<ul id="navbar-top-firstrow" class="nav-list" title="Navigation">
<li><a href="../../index.html">Overview</a></li>
<li class="nav-bar-cell1-rev">Package</li>
<li>Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../index-all.html">Index</a></li>
<li><a href="../../help-doc.html#package">Help</a></li>
</ul>
<ul class="sub-nav-list-small">
<li>
<p>Package:</p>
<ul>
<li><a href="#package-description">Description</a></li>
<li>Related Packages</li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</li>
</ul>
</div>
<div class="sub-nav">
<div id="navbar-sub-list">
<ul class="sub-nav-list">
<li>Package:&nbsp;</li>
<li><a href="#package-description">Description</a>&nbsp;|&nbsp;</li>
<li>Related Packages&nbsp;|&nbsp;</li>
<li><a href="#class-summary">Classes and Interfaces</a></li>
</ul>
</div>
<div class="nav-list-search"><a href="../../search.html">SEARCH</a>
<input type="text" id="search-input" disabled placeholder="Search">
<input type="reset" id="reset-button" disabled value="reset">
</div>
</div>
<!-- ========= END OF TOP NAVBAR ========= -->
<span class="skip-nav" id="skip-navbar-top"></span></nav>
</header>
<div class="flex-content">
<main role="main">
<div class="header">
<h1 title="Package smile.manifold" class="title">Package smile.manifold</h1>
</div>
<hr>
<div class="package-signature">package <span class="element-name">smile.manifold</span></div>
<section class="package-description" id="package-description">
<div class="block">Manifold learning finds a low-dimensional basis for describing
 high-dimensional data. Manifold learning is a popular approach to nonlinear
 dimensionality reduction. Algorithms for this task are based on the idea
 that the dimensionality of many data sets is only artificially high; though
 each data point consists of perhaps thousands of features, it may be
 described as a function of only a few underlying parameters. That is, the
 data points are actually samples from a low-dimensional manifold that is
 embedded in a high-dimensional space. Manifold learning algorithms attempt
 to uncover these parameters in order to find a low-dimensional representation
 of the data.
 <p>
 Some prominent approaches are locally linear embedding
 (LLE), Hessian LLE, Laplacian eigenmaps, and LTSA. These techniques
 construct a low-dimensional data representation using a cost function
 that retains local properties of the data, and can be viewed as defining
 a graph-based kernel for Kernel PCA. More recently, techniques have been
 proposed that, instead of defining a fixed kernel, try to learn the kernel
 using semidefinite programming. The most prominent example of such a
 technique is maximum variance unfolding (MVU). The central idea of MVU
 is to exactly preserve all pairwise distances between nearest neighbors
 (in the inner product space), while maximizing the distances between points
 that are not nearest neighbors.
 <p>
 An alternative approach to neighborhood preservation is through the
 minimization of a cost function that measures differences between
 distances in the input and output spaces. Important examples of such
 techniques include classical multidimensional scaling (which is identical
 to PCA), Isomap (which uses geodesic distances in the data space), diffusion
 maps (which uses diffusion distances in the data space), t-SNE (which
 minimizes the divergence between distributions over pairs of points),
 and curvilinear component analysis.
 <p>
 Multidimensional scaling is a set of related statistical techniques
 often used in information visualization for exploring similarities or
 dissimilarities in data. An MDS algorithm starts with a matrix of item-item
 similarities, then assigns a location to each item in N-dimensional space.
 For sufficiently small N, the resulting locations may be displayed in a
 graph or 3D visualization.
 <p>
 The major types of MDS algorithms include:
 <dl>
 <dt>Classical multidimensional scaling</dt>
 <dd>takes an input matrix giving dissimilarities between pairs of items and
 outputs a coordinate matrix whose configuration minimizes a loss function
 called strain.</dd>
 <dt>Metric multidimensional scaling</dt>
 <dd>A superset of classical MDS that generalizes the optimization procedure
 to a variety of loss functions and input matrices of known distances with
 weights and so on. A useful loss function in this context is called stress
 which is often minimized using a procedure called stress majorization.</dd>
 <dt>Non-metric multidimensional scaling</dt>
 <dd>In contrast to metric MDS, non-metric MDS finds both a non-parametric
 monotonic relationship between the dissimilarities in the item-item matrix
 and the Euclidean distances between items, and the location of each item in
 the low-dimensional space. The relationship is typically found using isotonic
 regression.</dd>
 <dt>Generalized multidimensional scaling</dt>
 <dd>An extension of metric multidimensional scaling, in which the target
 space is an arbitrary smooth non-Euclidean space. In case when the
 dissimilarities are distances on a surface and the target space is another
 surface, GMDS allows finding the minimum-distortion embedding of one surface
 into another.</dd>
 </dl></div>
</section>
<section class="summary">
<ul class="summary-list">
<li>
<div id="class-summary">
<div class="caption"><span>Classes</span></div>
<div class="summary-table two-column-summary">
<div class="table-header col-first">Class</div>
<div class="table-header col-last">Description</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="IsoMap.html" title="class in smile.manifold">IsoMap</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Isometric feature mapping.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="IsotonicMDS.html" title="class in smile.manifold">IsotonicMDS</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Kruskal's non-metric MDS.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="KPCA.html" title="class in smile.manifold">KPCA</a>&lt;T&gt;</div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Kernel principal component analysis.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="LaplacianEigenmap.html" title="class in smile.manifold">LaplacianEigenmap</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Laplacian Eigenmap.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="LLE.html" title="class in smile.manifold">LLE</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Locally Linear Embedding.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="MDS.html" title="class in smile.manifold">MDS</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">Classical multidimensional scaling, also known as principal coordinates
 analysis.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="SammonMapping.html" title="class in smile.manifold">SammonMapping</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">The Sammon's mapping is an iterative technique for making interpoint
 distances in the low-dimensional projection as close as possible to the
 interpoint distances in the high-dimensional object.</div>
</div>
<div class="col-first odd-row-color class-summary class-summary-tab2"><a href="TSNE.html" title="class in smile.manifold">TSNE</a></div>
<div class="col-last odd-row-color class-summary class-summary-tab2">
<div class="block">The t-distributed stochastic neighbor embedding.</div>
</div>
<div class="col-first even-row-color class-summary class-summary-tab2"><a href="UMAP.html" title="class in smile.manifold">UMAP</a></div>
<div class="col-last even-row-color class-summary class-summary-tab2">
<div class="block">Uniform Manifold Approximation and Projection.</div>
</div>
</div>
</div>
</li>
</ul>
</section>
</main>
<footer role="contentinfo">
<hr>
<p class="legal-copy"><small>Copyright &copy; 2010-2024 Haifeng Li. All rights reserved.
Use is subject to <a href="https://raw.githubusercontent.com/haifengl/smile/master/LICENSE">license terms.</a>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-57GD08QCML"></script></small></p>
</footer>
</div>
</div>
</body>
</html>
