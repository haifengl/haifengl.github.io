<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>smile.manifold documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Smile</span> <span class="project-version">2.3.0</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>smile</span></div></div></li><li class="depth-2 branch"><a href="smile.ai.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>ai</span></div></a></li><li class="depth-2 branch"><a href="smile.classification.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>classification</span></div></a></li><li class="depth-2 branch"><a href="smile.clustering.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>clustering</span></div></a></li><li class="depth-2 branch"><a href="smile.io.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>io</span></div></a></li><li class="depth-2 branch current"><a href="smile.manifold.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>manifold</span></div></a></li><li class="depth-2 branch"><a href="smile.mds.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>mds</span></div></a></li><li class="depth-2"><a href="smile.regression.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>regression</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="smile.manifold.html#var-isomap"><div class="inner"><span>isomap</span></div></a></li><li class="depth-1"><a href="smile.manifold.html#var-laplacian"><div class="inner"><span>laplacian</span></div></a></li><li class="depth-1"><a href="smile.manifold.html#var-lle"><div class="inner"><span>lle</span></div></a></li><li class="depth-1"><a href="smile.manifold.html#var-tsne"><div class="inner"><span>tsne</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">smile.manifold</h1><div class="doc"><pre class="plaintext">Manifold Learning
</pre></div><div class="public anchor" id="var-isomap"><h3>isomap</h3><div class="usage"><code>(isomap data k)</code><code>(isomap data k d c-isomap)</code></div><div class="doc"><pre class="plaintext">Isometric feature mapping. Isomap is a widely used low-dimensional embedding methods,
where geodesic distances on a weighted graph are incorporated with the
classical multidimensional scaling. Isomap is used for computing a
quasi-isometric, low-dimensional embedding of a set of high-dimensional
data points. Isomap is highly efficient and generally applicable to a broad
range of data sources and dimensionalities.</pre></div></div><div class="public anchor" id="var-laplacian"><h3>laplacian</h3><div class="usage"><code>(laplacian data k)</code><code>(laplacian data k d t)</code></div><div class="doc"><pre class="plaintext">Laplacian Eigenmap. Using the notion of the Laplacian of the nearest
neighbor adjacency graph, Laplacian Eigenmap compute a low dimensional
representation of the dataset that optimally preserves local neighborhood
information in a certain sense. The representation map generated by the
algorithm may be viewed as a discrete approximation to a continuous map
that naturally arises from the geometry of the manifold.</pre></div></div><div class="public anchor" id="var-lle"><h3>lle</h3><div class="usage"><code>(lle data k)</code><code>(lle data k d)</code></div><div class="doc"><pre class="plaintext">Locally Linear Embedding. It has several advantages over Isomap, including
faster optimization when implemented to take advantage of sparse matrix
algorithms, and better results with many problems. LLE also begins by
finding a set of the nearest neighbors of each point. It then computes
a set of weights for each point that best describe the point as a linear
combination of its neighbors. Finally, it uses an eigenvector-based
optimization technique to find the low-dimensional embedding of points,
such that each point is still described with the same linear combination
of its neighbors. LLE tends to handle non-uniform sample densities poorly
because there is no fixed unit to prevent the weights from drifting as
various regions differ in sample densities.</pre></div></div><div class="public anchor" id="var-tsne"><h3>tsne</h3><div class="usage"><code>(tsne data)</code><code>(tsne data d perplexity eta iterations)</code></div><div class="doc"><pre class="plaintext">t-distributed stochastic neighbor embedding. t-SNE is a nonlinear
dimensionality reduction technique that is particularly well suited
for embedding high-dimensional data into a space of two or three
dimensions, which can then be visualized in a scatter plot. Specifically,
it models each high-dimensional object by a two- or three-dimensional
point in such a way that similar objects are modeled by nearby points
and dissimilar objects are modeled by distant points.</pre></div></div></div></body></html>